{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from utils.data_utils import (DynamicBatchSampler, collate_fn, get_dataset,\n",
    "                              get_grouping, get_static_dataset,\n",
    "                              get_test_dataset, get_test_synthetic_dataset)\n",
    "from utils.optuna_utils import load_best_model\n",
    "from utils.result_utils import (inference, plot_3d_combined_pdfs, plot_pdf,\n",
    "                                report_results, generate_smooth_pdf, calculate_crps,\n",
    "                                calculate_wasserstein, calculate_var_metric,)\n",
    "from utils.train_utils import ComparisonQuantileLoss, TwoStageQuantileLoss, train\n",
    "from LinearRegression import LinearQuantileRegression\n",
    "from wasserstein_min import get_best_hybrid_pdf_params, get_best_lstm_pdf_params\n",
    "\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "taus = config[\"general\"][\"quantiles\"]\n",
    "validation_start_date = config[\"general\"][\"dates\"][\"validation_period\"][\"start_date\"]\n",
    "validation_end_date = config[\"general\"][\"dates\"][\"validation_period\"][\"end_date\"]\n",
    "test_start_date = config[\"general\"][\"dates\"][\"test_period\"][\"start_date\"]\n",
    "test_end_date = config[\"general\"][\"dates\"][\"test_period\"][\"end_date\"]\n",
    "loss_fn = TwoStageQuantileLoss(taus)\n",
    "test_loss_fn = ComparisonQuantileLoss(taus)\n",
    "results = {}\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "np.random.seed(config[\"general\"][\"seed\"])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if not os.path.exists(\"plots\"):\n",
    "    os.makedirs(\"plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_Model(\n",
      "  (normalize_lstm): LSTM(49, 16, batch_first=True, dropout=0.17780297705940562)\n",
      "  (normalize_module): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=128, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Dropout(p=0.17780297705940562, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (4): ELU(alpha=1.0)\n",
      "    (5): Dropout(p=0.17780297705940562, inplace=False)\n",
      "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (7): ELU(alpha=1.0)\n",
      "    (8): Dropout(p=0.17780297705940562, inplace=False)\n",
      "    (9): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (10): ELU(alpha=1.0)\n",
      "    (11): Dropout(p=0.17780297705940562, inplace=False)\n",
      "    (12): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (13): ELU(alpha=1.0)\n",
      "    (14): Dropout(p=0.17780297705940562, inplace=False)\n",
      "    (15): Linear(in_features=32, out_features=37, bias=True)\n",
      "  )\n",
      "  (market_lstm): LSTM(21, 16, batch_first=True, dropout=0.17780297705940562)\n",
      "  (market_module): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Dropout(p=0.17780297705940562, inplace=False)\n",
      "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (4): Tanh()\n",
      "    (5): Dropout(p=0.17780297705940562, inplace=False)\n",
      "    (6): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (7): Tanh()\n",
      "    (8): Dropout(p=0.17780297705940562, inplace=False)\n",
      "    (9): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Model has 26854 parameters\n"
     ]
    }
   ],
   "source": [
    "lstm_model, lstm_params = load_best_model('lstm')\n",
    "\n",
    "lstm_model.to(DEVICE)\n",
    "\n",
    "lstm_normalization_window = lstm_params['normalazation_window']\n",
    "lstm_batch_size = lstm_params['batch_size']\n",
    "l1_reg = lstm_params['l1_reg']\n",
    "l2_reg = lstm_params['l2_reg']\n",
    "\n",
    "lstm_optimizer = torch.optim.Adam(lstm_model.parameters(\n",
    "), lr=lstm_params['learning_rate'], weight_decay=l2_reg)\n",
    "\n",
    "print(lstm_model)\n",
    "print(f\"Model has {sum(p.numel() for p in lstm_model.parameters() if p.requires_grad)} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'learning_rate': 0.0006301914928215536,\n",
       " 'normalazation_window': 219,\n",
       " 'raw_lstm_layers': 1,\n",
       " 'raw_lstm_h': 16,\n",
       " 'raw_hidden_layers': 5,\n",
       " 'raw_hidden_layer_0': 128,\n",
       " 'raw_hidden_layer_1': 64,\n",
       " 'raw_hidden_layer_2': 64,\n",
       " 'raw_hidden_layer_3': 32,\n",
       " 'raw_hidden_layer_4': 32,\n",
       " 'market_lstm_layers': 1,\n",
       " 'market_lstm_h': 16,\n",
       " 'market_hidden_layers': 3,\n",
       " 'market_hidden_layer_0': 16,\n",
       " 'market_hidden_layer_1': 16,\n",
       " 'market_hidden_layer_2': 32,\n",
       " 'dropout': 0.17780297705940562,\n",
       " 'market_activation': 'tanh',\n",
       " 'hidden_activation': 'elu',\n",
       " 'use_layer_norm': 0,\n",
       " 'l1_reg': 0.0005907317710879327,\n",
       " 'l2_reg': 0.0009171456011371559}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from lstm_model.pth\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('lstm_model.pth'):\n",
    "    lstm_model.load_state_dict(torch.load('lstm_model.pth'))\n",
    "    lstm_model.to(DEVICE)\n",
    "    print(\"Model loaded from lstm_model.pth\")\n",
    "else:\n",
    "    lstm_train_dataset = get_dataset(\n",
    "        lstm_normalization_window, \"1998-01-01\", validation_start_date)\n",
    "    lstm_val_dataset = get_dataset(lstm_normalization_window,\n",
    "                                   validation_start_date, validation_end_date)\n",
    "    lstm_train_batch_sampler = DynamicBatchSampler(\n",
    "        lstm_train_dataset, batch_size=lstm_batch_size)\n",
    "    lstm_val_batch_sampler = DynamicBatchSampler(lstm_val_dataset, batch_size=lstm_batch_size)\n",
    "\n",
    "    lstm_train_loader = DataLoader(\n",
    "        lstm_train_dataset, batch_sampler=lstm_train_batch_sampler, collate_fn=collate_fn)\n",
    "    lstm_val_loader = DataLoader(\n",
    "        lstm_val_dataset, batch_sampler=lstm_val_batch_sampler, collate_fn=collate_fn)\n",
    "    \n",
    "    _, lstm_model = train(\n",
    "        model=lstm_model,\n",
    "        train_loader=lstm_train_loader,\n",
    "        val_loader=lstm_val_loader,\n",
    "        criterion=loss_fn,\n",
    "        optimizer=lstm_optimizer,\n",
    "        num_epochs=100,\n",
    "        patience=10,\n",
    "        l1_reg=l1_reg,\n",
    "        lstm=False,\n",
    "        verbose=True\n",
    "    )\n",
    "    torch.save(lstm_model.state_dict(), 'lstm_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantileDense(\n",
      "  (raw_layers): ModuleList(\n",
      "    (0): Linear(in_features=49, out_features=32, bias=True)\n",
      "    (1): Dropout(p=0.46228174569794733, inplace=False)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (4): Dropout(p=0.46228174569794733, inplace=False)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (7): Dropout(p=0.46228174569794733, inplace=False)\n",
      "    (8): LeakyReLU(negative_slope=0.01)\n",
      "    (9): Linear(in_features=64, out_features=37, bias=True)\n",
      "  )\n",
      "  (raw_model): Sequential(\n",
      "    (0): Linear(in_features=49, out_features=32, bias=True)\n",
      "    (1): Dropout(p=0.46228174569794733, inplace=False)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (4): Dropout(p=0.46228174569794733, inplace=False)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (7): Dropout(p=0.46228174569794733, inplace=False)\n",
      "    (8): LeakyReLU(negative_slope=0.01)\n",
      "    (9): Linear(in_features=64, out_features=37, bias=True)\n",
      "  )\n",
      "  (market_layers): ModuleList(\n",
      "    (0): Linear(in_features=21, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.46228174569794733, inplace=False)\n",
      "    (2): ELU(alpha=1.0)\n",
      "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      "  (market_model): Sequential(\n",
      "    (0): Linear(in_features=21, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.46228174569794733, inplace=False)\n",
      "    (2): ELU(alpha=1.0)\n",
      "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dense_model, dense_params = load_best_model('dense')\n",
    "\n",
    "dense_model.to(DEVICE)\n",
    "\n",
    "dense_normalization_window = dense_params['normalazation_window']\n",
    "dense_batch_size = dense_params['batch_size']\n",
    "l1_reg = dense_params['l1_reg']\n",
    "l2_reg = dense_params['l2_reg']\n",
    "\n",
    "dense_optimizer = torch.optim.Adam(dense_model.parameters(), lr=dense_params['learning_rate'], weight_decay=l2_reg)\n",
    "\n",
    "print(dense_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'learning_rate': 0.00026207935278322914,\n",
       " 'normalazation_window': 207,\n",
       " 'n_raw_hidden_layers': 3,\n",
       " 'raw_hidden_layer_0': 32,\n",
       " 'raw_hidden_layer_1': 32,\n",
       " 'raw_hidden_layer_2': 64,\n",
       " 'hidden_activation': 'leaky_relu',\n",
       " 'n_market_hidden_layers': 1,\n",
       " 'market_hidden_layer_0': 64,\n",
       " 'market_activation': 'elu',\n",
       " 'dropout': 0.46228174569794733,\n",
       " 'layer_norm': 0,\n",
       " 'l1_reg': 0.00048765570640181864,\n",
       " 'l2_reg': 0.00012167657515795093}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from dense_model.pth\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('dense_model.pth'):\n",
    "    dense_model.load_state_dict(torch.load('dense_model.pth'))\n",
    "    dense_model.to(DEVICE)\n",
    "    print(\"Model loaded from dense_model.pth\")\n",
    "else:\n",
    "    dense_train_dataset = get_static_dataset(dense_normalization_window, \"1998-01-01\", validation_start_date)\n",
    "    dense_val_dataset = get_static_dataset(dense_normalization_window, validation_start_date, validation_end_date)\n",
    "\n",
    "    dense_train_loader = DataLoader(dense_train_dataset, batch_size=dense_batch_size, shuffle=True)\n",
    "    dense_val_loader = DataLoader(dense_val_dataset, batch_size=dense_batch_size, shuffle=False)\n",
    "    _, dense_model = train(\n",
    "        model=dense_model,\n",
    "        train_loader=dense_train_loader,\n",
    "        val_loader=dense_val_loader,\n",
    "        criterion=loss_fn,\n",
    "        optimizer=dense_optimizer,\n",
    "        num_epochs=100,\n",
    "        patience=10,\n",
    "        l1_reg=l1_reg,\n",
    "        verbose=True\n",
    "    )\n",
    "    torch.save(dense_model.state_dict(), 'dense_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from quant_reg.pth\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"quant_reg.pth\"):\n",
    "    dense_train_dataset = get_static_dataset(dense_normalization_window, \"1998-01-01\", validation_start_date)\n",
    "\n",
    "    big_X = []\n",
    "    big_y = []\n",
    "    for i in range(len(dense_train_dataset)):\n",
    "        x, _, z, y, _ = dense_train_dataset[i]\n",
    "        xx = torch.cat((x, z))\n",
    "        y = y.view(-1).cpu().numpy()\n",
    "        big_X.append(xx.cpu().numpy())\n",
    "        big_y.append(y)\n",
    "    big_X = np.array(big_X)\n",
    "    big_y = np.array(big_y).reshape(-1)\n",
    "\n",
    "    quant_reg = LinearQuantileRegression(taus)\n",
    "    quant_reg.train(big_X, big_y)\n",
    "\n",
    "    with open(\"quant_reg.pth\", \"wb\") as f:\n",
    "        pickle.dump(quant_reg, f)\n",
    "else:\n",
    "    with open(\"quant_reg.pth\", \"rb\") as f:\n",
    "        quant_reg = pickle.load(f)\n",
    "    print(\"Model loaded from quant_reg.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_test_dataset = get_test_dataset(dense_normalization_window, test_start_date, test_end_date)\n",
    "lstm_test_dataset = get_test_dataset(lstm_normalization_window, test_start_date, test_end_date, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = dense_test_dataset.assets\n",
    "datas = dense_test_dataset.datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b434b973d1f14c7eb799f586af6dcc4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inferencing models:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "for asset in tqdm(assets, desc='Inferencing models'):\n",
    "    grouping = get_grouping(datas, asset)\n",
    "    if grouping not in results:\n",
    "        results[grouping] = {\n",
    "            'linear': 0,\n",
    "            'dense': 0,\n",
    "            'lstm': 0,\n",
    "            'hybrid': 0\n",
    "        }\n",
    "    dense_test_dataset.set_main_asset(asset)\n",
    "    lstm_test_dataset.set_main_asset(asset)\n",
    "\n",
    "    dense_data_loader = DataLoader(dense_test_dataset, batch_size=1024, shuffle=False)\n",
    "    lstm_data_loader = DataLoader(lstm_test_dataset, batch_size=1024, shuffle=False)\n",
    "    dense_losses = inference(dense_model, dense_data_loader, test_loss_fn, is_dense=True)\n",
    "    lstm_losses = inference(lstm_model, lstm_data_loader, test_loss_fn, is_dense=False)\n",
    "    hybrid_losses = inference(lstm_model, lstm_data_loader, test_loss_fn,\n",
    "                              is_dense=False, hybrid=True, quant_probs=np.array(taus))\n",
    "    linear_loss = inference(quant_reg, dense_data_loader, test_loss_fn, is_dense=False,\n",
    "                            is_linear=True)\n",
    "\n",
    "    results[grouping]['linear'] += linear_loss.mean().item()\n",
    "    results[grouping]['dense'] += dense_losses.mean().item()\n",
    "    results[grouping]['lstm'] += lstm_losses.mean().item()\n",
    "    results[grouping]['hybrid'] += hybrid_losses.mean().item()\n",
    "results = {k: {model: value / 10 for model, value in v.items()} for k, v in results.items()}\n",
    "market_results = results.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  linear   dense    lstm  hybrid Difference (Dense - LSTM) Difference (Linear - LSTM) Difference (Linear - Dense)\n",
      "commodities       1.4815  0.4136  0.3223  0.3693           0.0913 (24.80%)           1.1592 (128.53%)            1.0680 (112.71%)\n",
      "cryptocurrencies  2.4931  2.2843  1.0222  1.2323           1.2621 (76.34%)            1.4709 (83.69%)              0.2088 (8.74%)\n",
      "s&p 500           1.4811  0.4255  0.3150  0.3572           0.1105 (29.85%)           1.1661 (129.85%)            1.0556 (110.73%)\n",
      "nikkei 225        1.4739  0.3991  0.3141  0.3552           0.0851 (23.85%)           1.1598 (129.74%)            1.0748 (114.76%)\n",
      "euro stoxx 50     1.4772  0.4184  0.3124  0.3520           0.1060 (29.02%)           1.1648 (130.17%)            1.0587 (111.70%)\n",
      "currency pairs    1.2003  0.0788  0.1528  0.0973         -0.0740 (-63.92%)           1.0476 (154.84%)            1.1216 (175.37%)\n",
      "Total Mean        1.6012  0.6699  0.4065  0.4606           0.2635 (48.96%)           1.1947 (119.02%)             0.9312 (82.01%)\n"
     ]
    }
   ],
   "source": [
    "report_results(market_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Normally Distributed Test Dataset\n",
      "Generated mu: -0.000147, sigma: 0.029948\n",
      "Generated mu: -0.000703, sigma: 0.014363\n",
      "Generated mu: 0.000283, sigma: 0.027260\n",
      "Generated mu: 0.000347, sigma: 0.025946\n",
      "Generated mu: 0.000642, sigma: 0.026121\n",
      "Generated mu: -0.000287, sigma: 0.020443\n",
      "Generated mu: -0.000927, sigma: 0.011248\n",
      "Generated mu: -0.000059, sigma: 0.025304\n",
      "Generated mu: -0.000578, sigma: 0.026805\n",
      "Generated mu: -0.000004, sigma: 0.027917\n",
      "Asset 1 correlation with market data: 0.6769\n",
      "Asset 2 correlation with market data: 0.6901\n",
      "Asset 3 correlation with market data: 0.6870\n",
      "Asset 4 correlation with market data: 0.7226\n",
      "Asset 5 correlation with market data: 0.6827\n",
      "Asset 6 correlation with market data: 0.7172\n",
      "Asset 7 correlation with market data: 0.7084\n",
      "Asset 8 correlation with market data: 0.6873\n",
      "Asset 9 correlation with market data: 0.6836\n",
      "Asset 10 correlation with market data: 0.7271\n",
      "Generating Log Normally Distributed Test Dataset\n",
      "Generated mu: -0.000182, sigma: 0.013624\n",
      "Generated mu: 0.000052, sigma: 0.026966\n",
      "Generated mu: -0.000191, sigma: 0.026462\n",
      "Generated mu: 0.000293, sigma: 0.015755\n",
      "Generated mu: 0.000847, sigma: 0.018568\n",
      "Generated mu: -0.000736, sigma: 0.025981\n",
      "Generated mu: 0.000153, sigma: 0.015571\n",
      "Generated mu: -0.000975, sigma: 0.026229\n",
      "Generated mu: 0.000684, sigma: 0.024038\n",
      "Generated mu: 0.000153, sigma: 0.010664\n",
      "Asset 1 correlation with market data: 0.6932\n",
      "Asset 2 correlation with market data: 0.7089\n",
      "Asset 3 correlation with market data: 0.6893\n",
      "Asset 4 correlation with market data: 0.7159\n",
      "Asset 5 correlation with market data: 0.6916\n",
      "Asset 6 correlation with market data: 0.7055\n",
      "Asset 7 correlation with market data: 0.7233\n",
      "Asset 8 correlation with market data: 0.6882\n",
      "Asset 9 correlation with market data: 0.7001\n",
      "Asset 10 correlation with market data: 0.6942\n",
      "Generating Gamma Distributed Test Dataset\n",
      "Generated mu: 0.000870, sigma: 0.018115\n",
      "Generated mu: 0.000159, sigma: 0.026306\n",
      "Generated mu: -0.000536, sigma: 0.028835\n",
      "Generated mu: -0.000702, sigma: 0.013297\n",
      "Generated mu: -0.000658, sigma: 0.016169\n",
      "Generated mu: 0.000232, sigma: 0.023341\n",
      "Generated mu: 0.000377, sigma: 0.021807\n",
      "Generated mu: 0.000902, sigma: 0.020885\n",
      "Generated mu: -0.000933, sigma: 0.026375\n",
      "Generated mu: 0.000619, sigma: 0.017544\n",
      "Asset 1 correlation with market data: 0.6991\n",
      "Asset 2 correlation with market data: 0.7003\n",
      "Asset 3 correlation with market data: 0.6784\n",
      "Asset 4 correlation with market data: 0.7080\n",
      "Asset 5 correlation with market data: 0.6806\n",
      "Asset 6 correlation with market data: 0.6983\n",
      "Asset 7 correlation with market data: 0.6930\n",
      "Asset 8 correlation with market data: 0.6991\n",
      "Asset 9 correlation with market data: 0.7111\n",
      "Asset 10 correlation with market data: 0.7142\n",
      "Generating Uniform Distributed Test Dataset\n",
      "Generated mu: -0.000004, sigma: 0.014595\n",
      "Generated mu: -0.000978, sigma: 0.012522\n",
      "Generated mu: -0.000604, sigma: 0.025999\n",
      "Generated mu: 0.000213, sigma: 0.021046\n",
      "Generated mu: -0.000413, sigma: 0.015879\n",
      "Generated mu: 0.000543, sigma: 0.017982\n",
      "Generated mu: 0.000160, sigma: 0.025962\n",
      "Generated mu: 0.000514, sigma: 0.028317\n",
      "Generated mu: -0.000334, sigma: 0.024776\n",
      "Generated mu: 0.000112, sigma: 0.023326\n",
      "Asset 1 correlation with market data: 0.8602\n",
      "Asset 2 correlation with market data: 0.8593\n",
      "Asset 3 correlation with market data: 0.8684\n",
      "Asset 4 correlation with market data: 0.8591\n",
      "Asset 5 correlation with market data: 0.8627\n",
      "Asset 6 correlation with market data: 0.8682\n",
      "Asset 7 correlation with market data: 0.8623\n",
      "Asset 8 correlation with market data: 0.8516\n",
      "Asset 9 correlation with market data: 0.8593\n",
      "Asset 10 correlation with market data: 0.8535\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating Normally Distributed Test Dataset\")\n",
    "dense_normal_test_dataset, lstm_normal_test_dataset = get_test_synthetic_dataset(\n",
    "    dense_normalization_window, lstm_normalization_window, 1000, 0.7, distribution='normal')\n",
    "print(\"Generating Log Normally Distributed Test Dataset\")\n",
    "dense_log_normal_test_dataset, lstm_log_normal_test_dataset = get_test_synthetic_dataset(\n",
    "    dense_normalization_window, lstm_normalization_window, 1000, 0.7, distribution='lognormal')\n",
    "print(\"Generating Gamma Distributed Test Dataset\")\n",
    "dense_gamma_test_dataset, lstm_gamma_test_dataset = get_test_synthetic_dataset(\n",
    "    dense_normalization_window, lstm_normalization_window, 1000, 0.7, distribution='gamma')\n",
    "print(\"Generating Uniform Distributed Test Dataset\")\n",
    "dense_uniform_test_dataset, lstm_uniform_test_dataset = get_test_synthetic_dataset(\n",
    "    dense_normalization_window, lstm_normalization_window, 1000, 0.7, distribution='uniform')\n",
    "\n",
    "synthetic_data = {\n",
    "    'Normal': (dense_normal_test_dataset, lstm_normal_test_dataset),\n",
    "    'Log Normal': (dense_log_normal_test_dataset, lstm_log_normal_test_dataset),\n",
    "    'Gamma': (dense_gamma_test_dataset, lstm_gamma_test_dataset),\n",
    "    'Uniform': (dense_uniform_test_dataset, lstm_uniform_test_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9d5c03fe544ec4846ed6b16ce768db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inferencing synthetic datasets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "synthetic_results = {}\n",
    "for distribution, (dense_synthetic_test_dataset, lstm_synthetic_test_dataset) in tqdm(synthetic_data.items(), desc='Inferencing synthetic datasets'):\n",
    "    dense_total_loss = 0\n",
    "    lstm_total_loss = 0\n",
    "    hybrid_total_losses = 0\n",
    "    for i in range(0, 10):\n",
    "        dense_synthetic_test_dataset.set_main_asset(f\"synthetic_{i}\")\n",
    "        lstm_synthetic_test_dataset.set_main_asset(f\"synthetic_{i}\")\n",
    "        dense_data_loader = DataLoader(dense_synthetic_test_dataset, batch_size=1024, shuffle=False)\n",
    "        lstm_data_loader = DataLoader(lstm_synthetic_test_dataset, batch_size=1024, shuffle=False)\n",
    "        linear_losses = inference(quant_reg, dense_data_loader,\n",
    "                                  test_loss_fn, is_dense=False, is_linear=True)\n",
    "        dense_losses = inference(dense_model, dense_data_loader, test_loss_fn, is_dense=True)\n",
    "        lstm_losses = inference(lstm_model, lstm_data_loader, test_loss_fn, is_dense=False)\n",
    "        hybrid_losses = inference(lstm_model, lstm_data_loader, test_loss_fn,\n",
    "                                  is_dense=False, hybrid=True, quant_probs=np.array(taus))\n",
    "        dense_total_loss += dense_losses.mean().item()\n",
    "        lstm_total_loss += lstm_losses.mean().item()\n",
    "        hybrid_total_losses += hybrid_losses.mean().item()\n",
    "\n",
    "    dense_total_loss /= 10\n",
    "    lstm_total_loss /= 10\n",
    "    hybrid_total_losses /= 10\n",
    "\n",
    "    results[f\"{distribution} synthetic\"] = {\n",
    "        'linear': linear_losses.mean().item(),\n",
    "        'dense': dense_total_loss,\n",
    "        'lstm': lstm_total_loss,\n",
    "        'hybrid': hybrid_losses.mean().item()\n",
    "    }\n",
    "    synthetic_results[f\"{distribution} synthetic\"] = {\n",
    "        'linear': linear_losses.mean().item(),\n",
    "        'dense': dense_total_loss,\n",
    "        'lstm': lstm_total_loss,\n",
    "        'hybrid': hybrid_losses.mean().item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      linear   dense    lstm  hybrid Difference (Dense - LSTM) Difference (Linear - LSTM) Difference (Linear - Dense)\n",
      "Normal synthetic      0.5029  0.9338  0.4201  0.4572           0.5137 (75.89%)            0.0828 (17.95%)           -0.4308 (-59.98%)\n",
      "Log Normal synthetic  0.2115  0.7229  0.3230  0.1565           0.3999 (76.48%)          -0.1114 (-41.70%)          -0.5114 (-109.45%)\n",
      "Gamma synthetic       0.3260  0.8268  0.3642  0.2781           0.4627 (77.70%)          -0.0381 (-11.05%)           -0.5008 (-86.88%)\n",
      "Uniform synthetic     0.3366  0.6864  0.2940  0.3030           0.3924 (80.04%)            0.0425 (13.49%)           -0.3498 (-68.39%)\n",
      "Total Mean            0.3443  0.7925  0.3503  0.2987           0.4422 (77.38%)           -0.0060 (-1.74%)           -0.4482 (-78.86%)\n"
     ]
    }
   ],
   "source": [
    "report_results(synthetic_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      linear   dense    lstm  hybrid Difference (Dense - LSTM) Difference (Linear - LSTM) Difference (Linear - Dense)\n",
      "commodities           1.4815  0.4136  0.3223  0.3693           0.0913 (24.80%)           1.1592 (128.53%)            1.0680 (112.71%)\n",
      "cryptocurrencies      2.4931  2.2843  1.0222  1.2323           1.2621 (76.34%)            1.4709 (83.69%)              0.2088 (8.74%)\n",
      "s&p 500               1.4811  0.4255  0.3150  0.3572           0.1105 (29.85%)           1.1661 (129.85%)            1.0556 (110.73%)\n",
      "nikkei 225            1.4739  0.3991  0.3141  0.3552           0.0851 (23.85%)           1.1598 (129.74%)            1.0748 (114.76%)\n",
      "euro stoxx 50         1.4772  0.4184  0.3124  0.3520           0.1060 (29.02%)           1.1648 (130.17%)            1.0587 (111.70%)\n",
      "currency pairs        1.2003  0.0788  0.1528  0.0973         -0.0740 (-63.92%)           1.0476 (154.84%)            1.1216 (175.37%)\n",
      "Normal synthetic      0.5029  0.9338  0.4201  0.4572           0.5137 (75.89%)            0.0828 (17.95%)           -0.4308 (-59.98%)\n",
      "Log Normal synthetic  0.2115  0.7229  0.3230  0.1565           0.3999 (76.48%)          -0.1114 (-41.70%)          -0.5114 (-109.45%)\n",
      "Gamma synthetic       0.3260  0.8268  0.3642  0.2781           0.4627 (77.70%)          -0.0381 (-11.05%)           -0.5008 (-86.88%)\n",
      "Uniform synthetic     0.3366  0.6864  0.2940  0.3030           0.3924 (80.04%)            0.0425 (13.49%)           -0.3498 (-68.39%)\n",
      "Total Mean            1.0984  0.7190  0.3840  0.3958           0.3350 (60.74%)            0.7144 (96.39%)             0.3795 (41.76%)\n"
     ]
    }
   ],
   "source": [
    "report_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_quantiles(data_set, model):\n",
    "    all_estimated_quantiles = {}\n",
    "    group_names = [\n",
    "        \"cryptocurrencies\",\n",
    "        \"currency pairs\",\n",
    "        \"commodities\",\n",
    "        \"euro stoxx 50\",\n",
    "        \"s&p 500\",\n",
    "        \"nikkei 225\"\n",
    "    ]\n",
    "    for group_name in tqdm(group_names, desc='Inferencing models'):\n",
    "        group_assets = [a[\"asset\"] for a in data_set.datas[group_name]]\n",
    "        sub_values = {\n",
    "            \"observed_returns\": [],\n",
    "            \"future_returns\": [],\n",
    "            \"all_pred_quantiles\": [],\n",
    "        }\n",
    "        for asset in group_assets:\n",
    "            data_set.set_main_asset(asset)\n",
    "            data_loader = DataLoader(data_set, batch_size=1024, shuffle=False)\n",
    "            model.eval()\n",
    "            for x, s, z, y, obs in data_loader:\n",
    "                x, s, z, y = x.to(DEVICE), s.to(DEVICE), z.to(DEVICE), y.to(DEVICE)\n",
    "                s = s.mean(dim=1)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    _, estimated_quantiles = model(x, s, z)\n",
    "                sub_values[\"all_pred_quantiles\"].append(estimated_quantiles.detach().cpu().numpy())\n",
    "                sub_values[\"observed_returns\"].append(obs.cpu().numpy().squeeze())\n",
    "                sub_values[\"future_returns\"].append(y.cpu().numpy().squeeze())\n",
    "        if len(sub_values[\"observed_returns\"]) == 0:\n",
    "            continue\n",
    "        sub_values[\"observed_returns\"] = np.concatenate(sub_values[\"observed_returns\"], axis=0)\n",
    "        sub_values[\"future_returns\"] = np.concatenate(sub_values[\"future_returns\"], axis=0)/100\n",
    "        sub_values[\"all_pred_quantiles\"] = np.concatenate(sub_values[\"all_pred_quantiles\"], axis=0)/100\n",
    "        \n",
    "        all_estimated_quantiles[group_name] = sub_values\n",
    "    return all_estimated_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = get_test_dataset(lstm_normalization_window, validation_start_date, validation_end_date, lookforward=30, test=True)\n",
    "prediction_test_set = get_test_dataset(lstm_normalization_window, test_start_date, test_end_date, lookforward=30, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fec311d79f4ca7a1699632824e96bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inferencing models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9871635c81040adaa71d8f3d342f091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inferencing models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_values = get_all_quantiles(val_dataset, lstm_model) \n",
    "test_values = get_all_quantiles(prediction_test_set, lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 23:25:41,229] Using an existing study with name 'wasserstein_distance_qlstm' instead of creating a new one.\n",
      "[I 2025-01-14 23:25:41,343] Using an existing study with name 'wasserstein_distance_hybrid_qlstm' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "best_lstm_pdf_params = get_best_lstm_pdf_params(val_values)\n",
    "best_hybrid_pdf_params = get_best_hybrid_pdf_params(val_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, skew, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = [\n",
    "    \"cryptocurrencies\",\n",
    "    \"currency pairs\",\n",
    "    \"commodities\",\n",
    "    \"euro stoxx 50\",\n",
    "    \"s&p 500\",\n",
    "    \"nikkei 225\"\n",
    "]\n",
    "metrics = {}\n",
    "baseline = {}\n",
    "hybrid = {}\n",
    "counts = {}\n",
    "wass = {}\n",
    "varss = {}\n",
    "crps = {}\n",
    "for group_name in group_names:\n",
    "    group_assets = [a[\"asset\"] for a in prediction_test_set.datas[group_name]]\n",
    "    wass_groups = []\n",
    "    wass_base = []\n",
    "    wass_hybrid = []\n",
    "    vars_group = [[], [], []]\n",
    "    vars_base = [[], [], []]\n",
    "    vars_hybrid = [[], [], []]\n",
    "    crps_group = []\n",
    "    crps_base = []\n",
    "    crps_hybrid = []\n",
    "\n",
    "    sub_metrics = {\n",
    "        \"mean\": 0,\n",
    "        \"std\": 0,\n",
    "        \"kurtosis\": 0,\n",
    "        \"skewness\": 0,\n",
    "    }\n",
    "    base_sub_metrics = {\n",
    "        \"mean\": 0,\n",
    "        \"std\": 0,\n",
    "        \"kurtosis\": 0,\n",
    "        \"skewness\": 0,\n",
    "    }\n",
    "    hybrid_metrics = {\n",
    "        \"mean\": 0,\n",
    "        \"std\": 0,\n",
    "        \"kurtosis\": 0,\n",
    "        \"skewness\": 0,\n",
    "    }\n",
    "    pred_quantiles = test_values[group_name][\"all_pred_quantiles\"]\n",
    "    observed_returns = test_values[group_name][\"observed_returns\"]\n",
    "    future_returns = test_values[group_name][\"future_returns\"]\n",
    "    for i in range(len(pred_quantiles)):\n",
    "        estimated_quantiles = pred_quantiles[i]\n",
    "        \n",
    "        empirical_mean = np.mean(observed_returns[i])\n",
    "        empirical_std = np.std(observed_returns[i])\n",
    "        empirical_skewness = skew(observed_returns[i])\n",
    "        empirical_kurtosis = kurtosis(observed_returns[i])\n",
    "\n",
    "        baseline_quantiles = norm.ppf(np.array(taus), loc=empirical_mean, scale=empirical_std)\n",
    "        \n",
    "        hybrid_quantiles = (estimated_quantiles + baseline_quantiles)/2\n",
    "        # ensure that quantiles are monotonically increasing\n",
    "        for j in range(1, len(hybrid_quantiles)):\n",
    "            if hybrid_quantiles[j] < hybrid_quantiles[j-1]:\n",
    "                hybrid_quantiles[j] = hybrid_quantiles[j-1]\n",
    "        \n",
    "        \n",
    "        grid, pdf, cdf = generate_smooth_pdf(estimated_quantiles, np.array(taus), **best_lstm_pdf_params)\n",
    "        _, hybrid_pdf, hybrid_cdf = generate_smooth_pdf(hybrid_quantiles, np.array(taus), **best_hybrid_pdf_params)\n",
    "        \n",
    "        gaussian_cdf = norm.cdf(grid, loc=empirical_mean, scale=empirical_std)\n",
    "        gaussian_pdf = norm.pdf(grid, loc=empirical_mean, scale=empirical_std)\n",
    "        \n",
    "        est_mean = np.trapz(grid * pdf, grid)\n",
    "        est_variance = np.trapz((grid - est_mean)**2 * pdf, grid)\n",
    "        est_skewness = np.trapz(((grid - est_mean)/np.sqrt(est_variance))**3 * pdf, grid)\n",
    "        est_est_kurtosis = np.trapz(((grid - est_mean)/np.sqrt(est_variance))**4 * pdf, grid)\n",
    "        \n",
    "        hybrid_mean = np.trapz(grid * hybrid_pdf, grid)\n",
    "        hybrid_variance = np.trapz((grid - hybrid_mean)**2 * hybrid_pdf, grid)\n",
    "        hybrid_skewness = np.trapz(((grid - hybrid_mean)/np.sqrt(hybrid_variance))**3 * hybrid_pdf, grid)\n",
    "        hybrid_kurtosis = np.trapz(((grid - hybrid_mean)/np.sqrt(hybrid_variance))**4 * hybrid_pdf, grid)\n",
    "        \n",
    "        realized_mean = np.mean(future_returns[i])\n",
    "        realized_std = np.std(future_returns[i])\n",
    "        realized_skewness = skew(future_returns[i])\n",
    "        realized_kurtosis = kurtosis(future_returns[i])\n",
    "\n",
    "        sub_metrics[\"mean\"] += (est_mean - realized_mean)**2\n",
    "        sub_metrics[\"std\"] += (np.sqrt(est_variance) - realized_std)**2\n",
    "        sub_metrics[\"skewness\"] += (est_skewness - realized_skewness)**2\n",
    "        sub_metrics[\"kurtosis\"] += (est_est_kurtosis - realized_kurtosis)**2\n",
    "\n",
    "        base_sub_metrics[\"mean\"] += (empirical_mean - realized_mean)**2\n",
    "        base_sub_metrics[\"std\"] += (empirical_std - realized_std)**2\n",
    "        base_sub_metrics[\"skewness\"] += (empirical_skewness - realized_skewness)**2\n",
    "        base_sub_metrics[\"kurtosis\"] += (empirical_kurtosis - realized_kurtosis)**2\n",
    "        \n",
    "        hybrid_metrics[\"mean\"] += (hybrid_mean - realized_mean)**2\n",
    "        hybrid_metrics[\"std\"] += (np.sqrt(hybrid_variance) - realized_std)**2\n",
    "        hybrid_metrics[\"skewness\"] += (hybrid_skewness - realized_skewness)**2\n",
    "        hybrid_metrics[\"kurtosis\"] += (hybrid_kurtosis - realized_kurtosis)**2\n",
    "\n",
    "        wass_groups.append(calculate_wasserstein(cdf, grid, future_returns[i]))\n",
    "        wass_hybrid.append(calculate_wasserstein(hybrid_cdf, grid, future_returns[i]))\n",
    "        wass_base.append(calculate_wasserstein(gaussian_cdf, grid, future_returns[i]))\n",
    "        \n",
    "        crps_group.append(calculate_crps(cdf, future_returns[i]))\n",
    "        crps_base.append(calculate_crps(gaussian_cdf, future_returns[i]))\n",
    "        crps_hybrid.append(calculate_crps(hybrid_cdf, future_returns[i]))\n",
    "\n",
    "        vars_ = [0.05, 0.01, 0.00075]\n",
    "        for j, var in enumerate(vars_):\n",
    "            var_results = calculate_var_metric(\n",
    "                estimated_quantiles, hybrid_quantiles, future_returns[i], baseline_quantiles, var, taus)\n",
    "            vars_group[j].append(var_results[\"var_error_predicted\"])\n",
    "            vars_base[j].append(var_results[\"var_error_baseline\"])\n",
    "            vars_hybrid[j].append(var_results[\"var_error_hybrid\"])\n",
    "\n",
    "    metrics[group_name] = sub_metrics\n",
    "    baseline[group_name] = base_sub_metrics\n",
    "    hybrid[group_name] = hybrid_metrics\n",
    "    counts[group_name] = len(pred_quantiles)\n",
    "    wass[group_name] = {\n",
    "        \"qLSTM\": np.mean(wass_groups),\n",
    "        \"Hybrid\": np.mean(wass_hybrid),\n",
    "        \"Gaussian\": np.mean(wass_base),\n",
    "    }\n",
    "    crps[group_name] = {\n",
    "        \"qLSTM\": np.mean(crps_group),\n",
    "        \"Hybrid\": np.mean(crps_hybrid),\n",
    "        \"Gaussian\": np.mean(crps_base)\n",
    "    }\n",
    "    varss[group_name] = {}\n",
    "    for j, var in enumerate(vars_):\n",
    "         varss[group_name][f\"{var}\"] = {\n",
    "            \"qLSTM\": np.mean(vars_group[j]),\n",
    "            \"Hybrid\": np.mean(vars_hybrid[j]),\n",
    "            \"Gaussian\": np.mean(vars_base[j])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metrics)\n",
    "hybrid_df = pd.DataFrame(hybrid)\n",
    "base_df = pd.DataFrame(baseline)\n",
    "\n",
    "mean_df = pd.DataFrame(\n",
    "    {\"qLSTM\": df.loc[\"mean\"],\n",
    "     \"Hybrid\": hybrid_df.loc[\"mean\"],\n",
    "     \"Base\": base_df.loc[\"mean\"]}\n",
    ")\n",
    "std_df = pd.DataFrame(\n",
    "    {\"qLSTM\": df.loc[\"std\"],\n",
    "     \"Hybrid\": hybrid_df.loc[\"std\"],\n",
    "     \"Base\": base_df.loc[\"std\"]}\n",
    ")\n",
    "kurtosis_df = pd.DataFrame(\n",
    "    {\"qLSTM\": df.loc[\"kurtosis\"],\n",
    "     \"Hybrid\": hybrid_df.loc[\"kurtosis\"],\n",
    "     \"Base\": base_df.loc[\"kurtosis\"]}\n",
    ")\n",
    "skewness_df = pd.DataFrame(\n",
    "    {\"qLSTM\": df.loc[\"skewness\"],\n",
    "     \"Hybrid\": hybrid_df.loc[\"skewness\"],\n",
    "     \"Base\": base_df.loc[\"skewness\"]}\n",
    ")\n",
    "\n",
    "mean_df = mean_df.T\n",
    "std_df = std_df.T\n",
    "kurtosis_df = kurtosis_df.T\n",
    "skewness_df = skewness_df.T\n",
    "\n",
    "for col in mean_df.columns:\n",
    "    mean_df[col] = np.round(np.sqrt(mean_df[col]/counts[col]), 4)\n",
    "    std_df[col] = np.round(np.sqrt(std_df[col]/counts[col]), 4)\n",
    "    kurtosis_df[col] = np.round(np.sqrt(kurtosis_df[col]/counts[col]), 4)\n",
    "    skewness_df[col] = np.round(np.sqrt(skewness_df[col]/counts[col]), 4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Mean Squared Error\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cryptocurrencies</th>\n",
       "      <th>currency pairs</th>\n",
       "      <th>commodities</th>\n",
       "      <th>euro stoxx 50</th>\n",
       "      <th>s&amp;p 500</th>\n",
       "      <th>nikkei 225</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qLSTM</th>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hybrid</th>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base</th>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cryptocurrencies  currency pairs  commodities  euro stoxx 50  s&p 500  \\\n",
       "qLSTM             0.0118          0.0010       0.0034         0.0041   0.0032   \n",
       "Hybrid            0.0119          0.0020       0.0035         0.0043   0.0033   \n",
       "Base              0.0166          0.0013       0.0050         0.0059   0.0048   \n",
       "\n",
       "        nikkei 225  \n",
       "qLSTM       0.0034  \n",
       "Hybrid      0.0035  \n",
       "Base        0.0050  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Expected Mean Squared Error\")\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Standard Deviation Squared Error\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cryptocurrencies</th>\n",
       "      <th>currency pairs</th>\n",
       "      <th>commodities</th>\n",
       "      <th>euro stoxx 50</th>\n",
       "      <th>s&amp;p 500</th>\n",
       "      <th>nikkei 225</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qLSTM</th>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hybrid</th>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base</th>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cryptocurrencies  currency pairs  commodities  euro stoxx 50  s&p 500  \\\n",
       "qLSTM             0.0424          0.0287       0.0085         0.0091   0.0096   \n",
       "Hybrid            0.0400          0.0422       0.0088         0.0109   0.0112   \n",
       "Base              0.0330          0.0021       0.0077         0.0101   0.0099   \n",
       "\n",
       "        nikkei 225  \n",
       "qLSTM       0.0068  \n",
       "Hybrid      0.0084  \n",
       "Base        0.0074  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Expected Standard Deviation Squared Error\")\n",
    "std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Skewness Squared Error\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cryptocurrencies</th>\n",
       "      <th>currency pairs</th>\n",
       "      <th>commodities</th>\n",
       "      <th>euro stoxx 50</th>\n",
       "      <th>s&amp;p 500</th>\n",
       "      <th>nikkei 225</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qLSTM</th>\n",
       "      <td>1.1129</td>\n",
       "      <td>0.7186</td>\n",
       "      <td>0.7667</td>\n",
       "      <td>0.7770</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>0.7422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hybrid</th>\n",
       "      <td>1.1133</td>\n",
       "      <td>0.7030</td>\n",
       "      <td>0.7496</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.8145</td>\n",
       "      <td>0.7339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base</th>\n",
       "      <td>1.6036</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>1.0207</td>\n",
       "      <td>1.0598</td>\n",
       "      <td>1.1718</td>\n",
       "      <td>1.0596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cryptocurrencies  currency pairs  commodities  euro stoxx 50  s&p 500  \\\n",
       "qLSTM             1.1129          0.7186       0.7667         0.7770   0.8350   \n",
       "Hybrid            1.1133          0.7030       0.7496         0.7585   0.8145   \n",
       "Base              1.6036          0.9410       1.0207         1.0598   1.1718   \n",
       "\n",
       "        nikkei 225  \n",
       "qLSTM       0.7422  \n",
       "Hybrid      0.7339  \n",
       "Base        1.0596  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Expected Skewness Squared Error\")\n",
    "skewness_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Kurtosis Squared Error\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cryptocurrencies</th>\n",
       "      <th>currency pairs</th>\n",
       "      <th>commodities</th>\n",
       "      <th>euro stoxx 50</th>\n",
       "      <th>s&amp;p 500</th>\n",
       "      <th>nikkei 225</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qLSTM</th>\n",
       "      <td>8.1838</td>\n",
       "      <td>9.2768</td>\n",
       "      <td>8.9404</td>\n",
       "      <td>8.7593</td>\n",
       "      <td>8.7733</td>\n",
       "      <td>8.8889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hybrid</th>\n",
       "      <td>5.3220</td>\n",
       "      <td>4.4449</td>\n",
       "      <td>4.2748</td>\n",
       "      <td>4.0337</td>\n",
       "      <td>4.1521</td>\n",
       "      <td>4.1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base</th>\n",
       "      <td>4.3678</td>\n",
       "      <td>2.7381</td>\n",
       "      <td>2.8323</td>\n",
       "      <td>2.6574</td>\n",
       "      <td>3.1615</td>\n",
       "      <td>2.7176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cryptocurrencies  currency pairs  commodities  euro stoxx 50  s&p 500  \\\n",
       "qLSTM             8.1838          9.2768       8.9404         8.7593   8.7733   \n",
       "Hybrid            5.3220          4.4449       4.2748         4.0337   4.1521   \n",
       "Base              4.3678          2.7381       2.8323         2.6574   3.1615   \n",
       "\n",
       "        nikkei 225  \n",
       "qLSTM       8.8889  \n",
       "Hybrid      4.1221  \n",
       "Base        2.7176  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Expected Kurtosis Squared Error\")\n",
    "kurtosis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wasserstein Distance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cryptocurrencies</th>\n",
       "      <th>currency pairs</th>\n",
       "      <th>commodities</th>\n",
       "      <th>euro stoxx 50</th>\n",
       "      <th>s&amp;p 500</th>\n",
       "      <th>nikkei 225</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qLSTM</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hybrid</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cryptocurrencies  currency pairs  commodities  euro stoxx 50  \\\n",
       "qLSTM               0.0260          0.0179       0.0079         0.0077   \n",
       "Hybrid              0.0213          0.0194       0.0072         0.0079   \n",
       "Gaussian            0.0221          0.0017       0.0074         0.0081   \n",
       "\n",
       "          s&p 500  nikkei 225  \n",
       "qLSTM      0.0081      0.0075  \n",
       "Hybrid     0.0080      0.0071  \n",
       "Gaussian   0.0079      0.0074  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Wasserstein Distance\")\n",
    "wass_df = pd.DataFrame(wass)\n",
    "wass_df = np.round(wass_df, 4)\n",
    "wass_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRPS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cryptocurrencies</th>\n",
       "      <th>currency pairs</th>\n",
       "      <th>commodities</th>\n",
       "      <th>euro stoxx 50</th>\n",
       "      <th>s&amp;p 500</th>\n",
       "      <th>nikkei 225</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qLSTM</th>\n",
       "      <td>0.4320</td>\n",
       "      <td>0.4477</td>\n",
       "      <td>0.4422</td>\n",
       "      <td>0.4424</td>\n",
       "      <td>0.4422</td>\n",
       "      <td>0.4421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hybrid</th>\n",
       "      <td>0.4179</td>\n",
       "      <td>0.4464</td>\n",
       "      <td>0.4331</td>\n",
       "      <td>0.4340</td>\n",
       "      <td>0.4338</td>\n",
       "      <td>0.4334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian</th>\n",
       "      <td>0.3544</td>\n",
       "      <td>0.4793</td>\n",
       "      <td>0.4308</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.4369</td>\n",
       "      <td>0.4349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cryptocurrencies  currency pairs  commodities  euro stoxx 50  \\\n",
       "qLSTM               0.4320          0.4477       0.4422         0.4424   \n",
       "Hybrid              0.4179          0.4464       0.4331         0.4340   \n",
       "Gaussian            0.3544          0.4793       0.4308         0.4366   \n",
       "\n",
       "          s&p 500  nikkei 225  \n",
       "qLSTM      0.4422      0.4421  \n",
       "Hybrid     0.4338      0.4334  \n",
       "Gaussian   0.4369      0.4349  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"CRPS\")\n",
    "crps_df = pd.DataFrame(crps)\n",
    "crps_df = np.round(crps_df, 4)\n",
    "crps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var 0.05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cryptocurrencies</th>\n",
       "      <th>currency pairs</th>\n",
       "      <th>commodities</th>\n",
       "      <th>euro stoxx 50</th>\n",
       "      <th>s&amp;p 500</th>\n",
       "      <th>nikkei 225</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qLSTM</th>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.0499</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0609</td>\n",
       "      <td>0.0549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hybrid</th>\n",
       "      <td>0.0777</td>\n",
       "      <td>0.0492</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.0460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian</th>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.0536</td>\n",
       "      <td>0.0469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cryptocurrencies  currency pairs  commodities  euro stoxx 50  \\\n",
       "qLSTM               0.1967          0.0499       0.0659         0.0539   \n",
       "Hybrid              0.0777          0.0492       0.0481         0.0485   \n",
       "Gaussian            0.0505          0.0505       0.0466         0.0537   \n",
       "\n",
       "          s&p 500  nikkei 225  \n",
       "qLSTM      0.0609      0.0549  \n",
       "Hybrid     0.0506      0.0460  \n",
       "Gaussian   0.0536      0.0469  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = 0.05\n",
    "print(f\"Var {var}\")\n",
    "sub_varss = {}\n",
    "for group_name in group_names:\n",
    "    sub_varss[group_name] = varss[group_name][f\"{var}\"]\n",
    "var_df = pd.DataFrame(sub_varss)\n",
    "var_df = np.round(var_df, 4)\n",
    "var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var 0.01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cryptocurrencies</th>\n",
       "      <th>currency pairs</th>\n",
       "      <th>commodities</th>\n",
       "      <th>euro stoxx 50</th>\n",
       "      <th>s&amp;p 500</th>\n",
       "      <th>nikkei 225</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qLSTM</th>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.0176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hybrid</th>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian</th>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.0268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cryptocurrencies  currency pairs  commodities  euro stoxx 50  \\\n",
       "qLSTM               0.1085          0.0100       0.0206         0.0190   \n",
       "Hybrid              0.0478          0.0100       0.0203         0.0220   \n",
       "Gaussian            0.0298          0.0287       0.0262         0.0326   \n",
       "\n",
       "          s&p 500  nikkei 225  \n",
       "qLSTM      0.0208      0.0176  \n",
       "Hybrid     0.0215      0.0198  \n",
       "Gaussian   0.0322      0.0268  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = 0.01\n",
    "print(f\"Var {var}\")\n",
    "sub_varss = {}\n",
    "for group_name in group_names:\n",
    "    sub_varss[group_name] = varss[group_name][f\"{var}\"]\n",
    "var_df = pd.DataFrame(sub_varss)\n",
    "var_df = np.round(var_df, 4)\n",
    "var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var 0.00075\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cryptocurrencies</th>\n",
       "      <th>currency pairs</th>\n",
       "      <th>commodities</th>\n",
       "      <th>euro stoxx 50</th>\n",
       "      <th>s&amp;p 500</th>\n",
       "      <th>nikkei 225</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qLSTM</th>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hybrid</th>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian</th>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cryptocurrencies  currency pairs  commodities  euro stoxx 50  \\\n",
       "qLSTM               0.0353          0.0008       0.0028         0.0031   \n",
       "Hybrid              0.0176          0.0008       0.0036         0.0056   \n",
       "Gaussian            0.0139          0.0113       0.0104         0.0158   \n",
       "\n",
       "          s&p 500  nikkei 225  \n",
       "qLSTM      0.0024      0.0018  \n",
       "Hybrid     0.0047      0.0029  \n",
       "Gaussian   0.0157      0.0099  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = 0.00075\n",
    "print(f\"Var {var}\")\n",
    "sub_varss = {}\n",
    "for group_name in group_names:\n",
    "    sub_varss[group_name] = varss[group_name][f\"{var}\"]\n",
    "var_df = pd.DataFrame(sub_varss)\n",
    "var_df = np.round(var_df, 4)\n",
    "var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
